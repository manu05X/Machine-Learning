{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "Q>\n",
    "What is the dimension of output from\n",
    "tf.nn.softmax_cross_entropy_with_logits\n",
    "\n",
    "* Options\n",
    "        \n",
    "        Single Number\n",
    "        \n",
    "        N_input * 1\n",
    "        \n",
    "        N_classes * 1 \n",
    "        \n",
    "        N_classes * N_input\n",
    "\n",
    "Ans: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimizer\n",
    "Q>\n",
    "Running\n",
    "\n",
    "c, _ = sess.run([cost,optimizer], feed_dict={x:batch_x , y:batch_y}) \n",
    "\n",
    "\n",
    "will reduce the cost function?\n",
    "\n",
    "* Options\n",
    "        \n",
    "        True\n",
    "\n",
    "        False \n",
    "\n",
    "Correct Answer: False\n",
    "\n",
    "Explanation: You need to run optimize Just creating the optimizer isn’t enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimizer\n",
    "Q>\n",
    "Let’s assume that cost corresponding to a particular training set is ‘c1’ before running the optimizer once. It becomes ‘c2’ after running the optimizer once and ‘c3’ after running it twice. What will be the output of the following code?\n",
    "\n",
    "    c=sess.run(cost, feed_dict={x:batch_x , y:batch_y})\n",
    "    print(c)\n",
    "    c,_ = sess.run([cost, optimize], feed_dict={x:batch_x , y:batch_y})\n",
    "    print(c)\n",
    "    c,_ = sess.run([cost, optimize], feed_dict={x:batch_x , y:batch_y})\n",
    "    print(c)\n",
    "\n",
    "\n",
    "\n",
    "* Options\n",
    "        \n",
    "        c1, c2, c3\n",
    "        \n",
    "        c1, c1, c3\n",
    "        \n",
    "        c1, c2, c2\n",
    "        \n",
    "        c1, c1, c2 \n",
    "\n",
    "Correct Answer: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does the optimizer work?\n",
    "\n",
    "Q>\n",
    "What does the minimize function of optimizer do? (Hint: Read documentation)\n",
    "\n",
    "    c=sess.run(cost, feed_dict={x:batch_x , y:batch_y})\n",
    "    print(c)\n",
    "    c,_ = sess.run([cost, optimize], feed_dict={x:batch_x , y:batch_y})\n",
    "    print(c)\n",
    "    c,_ = sess.run([cost, optimize], feed_dict={x:batch_x , y:batch_y})\n",
    "    print(c)\n",
    "\n",
    "\n",
    "\n",
    "* Options\n",
    "        \n",
    "       * Tries various values of the variables and finds values which work well.\n",
    "       \n",
    "       * Finds the derivatives with respect to variables and puts them to zero. Using these equations it finds the best possible values to minimize the function.\n",
    "       \n",
    "       * Finds the derivative(slope) values & change the variable values as per the learning rate and the slopes once. \n",
    "       * Finds the derivative(slope) values & change the variable values as per the learning rate and the slopes repeatedly until convergence\n",
    "\n",
    "Correct Answer: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does the optimizer work?\n",
    "\n",
    "Q>\n",
    "What would be the effect of the line\n",
    "\n",
    "    optimize = optimizer.minimize(cost)\n",
    "\n",
    "if we change the code for declaring weights to:\n",
    "\n",
    "        n_input = 784\n",
    "        n_hidden_1 = 256\n",
    "        n_hidden_2 = 256\n",
    "        n_classes = 10\n",
    "\n",
    "        weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), trainable=False),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), trainable=False),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), trainable=False)\n",
    "        }\n",
    "\n",
    "        biases = {\n",
    "        'h1': tf.Variable(tf.random_normal([n_hidden_1]), trainable=False),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_2]), trainable=False),\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]), trainable=False)\n",
    "        }\n",
    "\n",
    "* Options\n",
    "        \n",
    "       * Same as what we discussed in lecture.\n",
    "       \n",
    "       * Cost will stay the same even after running the minimize function.\n",
    "       \n",
    "       * Error. \n",
    "       \n",
    "       * It will minimize the cost function with respect to other variables.\n",
    "\n",
    "Correct Answer: 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
