{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-a742f5717139>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-a742f5717139>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocess\"\"\"\n",
    "this script is used to generate Logistic Regression (classification) model in order to predict the breast cancer prognosis\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# *** FUNCTIONS ***\n",
    "def calculate_confusion_matrix_values(df, predicted_indicator, actual_indicator):\n",
    "    \"\"\"\n",
    "    calculates true positive, true negative, false positive, false negative\n",
    "    :param df: a data frame with both predicted and actual values\n",
    "    :param predicted_indicator: values are 0 or 1\n",
    "    :param actual_indicator: values are 0 or 1\n",
    "    :return: a confusion matrix value: true positive, true negative, false positive, false negative\n",
    "    \"\"\"\n",
    "    df = df[df[\"predicted_label\"] == predicted_indicator]\n",
    "    df = df[df[\"outcome_integer\"] == actual_indicator]\n",
    "    return df.shape[0]\n",
    "\n",
    "def model_performance_metrics(wpbc_df):\n",
    "    \"\"\"\n",
    "    calculates model performance\n",
    "    :param wpbc_df: data frame with predicted and actual columns\n",
    "    :return: true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity, fall_out_rate\n",
    "    \"\"\"\n",
    "    true_positives = calculate_confusion_matrix_values(wpbc_df,1,1)\n",
    "    true_negatives = calculate_confusion_matrix_values(wpbc_df,0,0)\n",
    "    false_negatives = calculate_confusion_matrix_values(wpbc_df,0,1)\n",
    "    false_positives = calculate_confusion_matrix_values(wpbc_df,1,0)\n",
    "    sensitivity = float(true_positives) / float(true_positives + false_negatives)\n",
    "    specificity = float(true_negatives) / float(false_positives + true_negatives)\n",
    "    fall_out_rate = float(false_positives) / float(false_positives + true_negatives)\n",
    "    return true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity, fall_out_rate\n",
    "\n",
    "def model_on_whole_data_set(wpbc_df, features):\n",
    "    \"\"\"\n",
    "    fit the model on the whole list (not dividing the data into train and test data sets)\n",
    "    :param wpbc_df: data frame that will be used to create the model\n",
    "    :param features: the independent variables used to generate the model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # *** lets fit the model on the whole list (not dividing the data into train and test data sets) ***\n",
    "    #create a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(wpbc_df[features], wpbc_df[\"outcome_integer\"])\n",
    "\n",
    "    outcome_prediction = model.predict(wpbc_df[features])\n",
    "    wpbc_df[\"predicted_label\"] = outcome_prediction\n",
    "    print(wpbc_df[\"predicted_label\"].value_counts())\n",
    "\n",
    "    #calculate accuracy of the model\n",
    "    matches = wpbc_df[\"predicted_label\"] == wpbc_df[\"outcome_integer\"]\n",
    "    correct_predictions = wpbc_df[matches]\n",
    "    print(correct_predictions.head())\n",
    "    accuracy = float(len(correct_predictions)) / float(len(wpbc_df))\n",
    "    print(\"Accuracy: {0}\".format(accuracy))\n",
    "\n",
    "    #Sensitivity and Specificity\n",
    "    true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity, fall_out_rate = model_performance_metrics(wpbc_df)\n",
    "\n",
    "    print(\"True Positive: {0}\".format(true_positives))\n",
    "    print(\"True Negative: {0}\".format(true_negatives))\n",
    "    print(\"False Negative: {0}\".format(false_negatives))\n",
    "    print(\"False Positive: {0}\".format(false_positives))\n",
    "    print(\"Sensitivity: {0}\".format(sensitivity))\n",
    "    print(\"Specificity: {0}\".format(specificity))\n",
    "    print(\"Fall Out Rate: {0}\".format(fall_out_rate))\n",
    "\n",
    "    #ROC\n",
    "    probabilities = model.predict_proba(wpbc_df[features])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(wpbc_df[\"outcome_integer\"], probabilities[:,1])\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.show()\n",
    "\n",
    "    #AUC\n",
    "    auc_score = roc_auc_score(wpbc_df[\"outcome_integer\"],probabilities[:,1])\n",
    "    print(\"AUC Score: {0}\".format(auc_score))\n",
    "\n",
    "def model_using_holdout_validation(wpbc_df, features):\n",
    "    \"\"\"\n",
    "    fit model on a train and predict a test data frame\n",
    "    :param wpbc_df: data frame that will be used to create the model\n",
    "    :param features: the independent variables used to generate the model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    #create train and test data sets\n",
    "    train_df, test_df = create_train_test(wpbc_df)\n",
    "\n",
    "    #create a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_df[features], train_df[\"outcome_integer\"])\n",
    "\n",
    "    predictions = model.predict(test_df[features])\n",
    "    test_df[\"predicted_label\"] = predictions\n",
    "\n",
    "    matches = test_df[\"predicted_label\"] == test_df[\"outcome_integer\"]\n",
    "    correct_predictions = test_df[matches]\n",
    "    accuracy = float(len(correct_predictions)) / float(len(test_df))\n",
    "    print(\"Accuracy: {0}\".format(accuracy))\n",
    "\n",
    "    #Sensitivity and Specificity\n",
    "    true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity, fall_out_rate = model_performance_metrics(test_df)\n",
    "    print(\"True Positive: {0}\".format(true_positives))\n",
    "    print(\"True Negative: {0}\".format(true_negatives))\n",
    "    print(\"False Negative: {0}\".format(false_negatives))\n",
    "    print(\"False Positive: {0}\".format(false_positives))\n",
    "    print(\"Sensitivity: {0}\".format(sensitivity))\n",
    "    print(\"Specificity: {0}\".format(specificity))\n",
    "    print(\"Fall Out Rate: {0}\".format(fall_out_rate))\n",
    "\n",
    "    #ROC\n",
    "    probabilities = model.predict_proba(test_df[features])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_df[\"outcome_integer\"], probabilities[:,1])\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.show()\n",
    "\n",
    "    #AUC\n",
    "    auc_score = roc_auc_score(test_df[\"outcome_integer\"],probabilities[:,1])\n",
    "    print(\"AUC Score: {0}\".format(auc_score))\n",
    "\n",
    "def create_train_test(df):\n",
    "    \"\"\"\n",
    "    breaks the panadas data frame into train and test data sets. 80/20\n",
    "    :param df: the data frame to be broken up\n",
    "    :return: train and test data frames\n",
    "    \"\"\"\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    shuffled_df = df.loc[shuffled_index]\n",
    "    #train is 80% of the shuffled list\n",
    "    train_length = int(np.ceil(len(shuffled_index) * 0.80))\n",
    "    train_df = shuffled_df[0:train_length]\n",
    "    test_df = shuffled_df[train_length:len(shuffled_df)]\n",
    "    return train_df, test_df\n",
    "\n",
    "def prepare_df(file):\n",
    "    \"\"\"\n",
    "    cleans up the input file\n",
    "    :param file: the input file\n",
    "    :return: data frame of the cleaned and modified data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wpbc_df = pd.read_csv(file, sep=\",\")\n",
    "    except:\n",
    "        print(\"Error opening file\")\n",
    "        sys.exit(1)\n",
    "    print(\"there are {0} rows in the data set\".format(len(wpbc_df)))\n",
    "    #clean up: some rows have '?' in lymph_node_status. Lets see how many rows are there with '?'\n",
    "    temp_df = wpbc_df[wpbc_df[\"lymph_node_status\"] == '?']\n",
    "    print(\"there are {0} rows with '?' in lymph_node_status column\".format(len(temp_df)))\n",
    "    #there were only 4 rows where lymph_node_status = '?'. So I will delete these 4 rows\n",
    "    wpbc_df = wpbc_df[wpbc_df[\"lymph_node_status\"] != '?']\n",
    "    print(\"there are now {0} rows in the data set\".format(len(wpbc_df)))\n",
    "    #create an integer equivalent of 'outcome'\n",
    "    wpbc_df[\"outcome_integer\"] = [0 if x == \"N\" else 1 for x in wpbc_df[\"outcome\"]]\n",
    "    return wpbc_df\n",
    "\n",
    "def get_data_with_folds(wpbc_df, folds):\n",
    "    rows_per_fold = int(np.ceil(float(len(wpbc_df)) / float(folds)))\n",
    "    print(\"Rows Per Fold: {0}\".format(rows_per_fold))\n",
    "\n",
    "    #shuffle the data frame\n",
    "    shuffled_index = np.random.permutation(wpbc_df.index)\n",
    "    shuffled_admissions = wpbc_df.loc[shuffled_index]\n",
    "    wpbc_df = shuffled_admissions.reset_index()\n",
    "    start = 0\n",
    "    end = rows_per_fold\n",
    "    for i in range(1,folds+1):\n",
    "        wpbc_df.ix[start:end, \"fold\"] = i\n",
    "        start = end + 1\n",
    "        end = end + rows_per_fold + 1\n",
    "\n",
    "    wpbc_df[\"fold\"] = wpbc_df[\"fold\"].astype('int')\n",
    "    return wpbc_df\n",
    "\n",
    "def train_and_test_kfold(df, features, lst):\n",
    "    accuracies_lst = []\n",
    "    for i in lst:\n",
    "        model = LogisticRegression()\n",
    "        train = df[df[\"fold\"] != i]\n",
    "        test = df[df[\"fold\"] == i]\n",
    "        model.fit(train[features],train[\"outcome_integer\"])\n",
    "        labels = model.predict(test[features])\n",
    "        test[\"predicted_label\"] = labels\n",
    "        correct_predictions = test[test[\"predicted_label\"] == test[\"outcome_integer\"]]\n",
    "        accuracies_lst.append(float(len(correct_predictions))/float(len(test)))\n",
    "    return accuracies_lst\n",
    "\n",
    "\n",
    "\n",
    "def model_using_kfold_cross_validation(wpbc_df, features, folds):\n",
    "    wpbc_df = get_data_with_folds(wpbc_df, folds)\n",
    "    accuracies = train_and_test_kfold(wpbc_df, features, [1, 2, 3, 4, 5])\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    print(\"Average Accuracy using my kfold cross validation: {0}\".format(average_accuracy))\n",
    "\n",
    "# *** END FUNCTIONS\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    the main function handles command line inputs and create the model/predictions based on the input parameter\n",
    "    :arg1: \"ALL\" to run the model against the whole data. \"HOLDOUT\" to do an 80/20 holdout validation and run the model on the 80 and test on the 20\n",
    "    :return: status 1 if error, 0 if success\n",
    "    \"\"\"\n",
    "    status = True\n",
    "    use = '''Usage: %prog model_method\n",
    "    model_method: \"ALL\", \"HOLDOUT\"\n",
    "    '''\n",
    "    parser = OptionParser(usage=use)\n",
    "    (options, args) = parser.parse_args()\n",
    "    if len(args) != 1:\n",
    "        parser.error(\"incorrect number of arguments\")\n",
    "        status = False\n",
    "    else:\n",
    "        features = ['recurrence_time', 'cell_radius','cell_texture','cell_perimeter','cell_area','cell_smoothness','cell_compactness', \\\n",
    "                    'cell_concave_points','cell_symmetry','cell_fractal_dimension','cell_11','cell_12','cell_13','cell_14','cell_15', \\\n",
    "                    'cell_16','cell_17','cell_18','cell_19','cell_20','cell_21','cell_22','cell_23','cell_24','cell_25','cell_26','cell_27', \\\n",
    "                    'cell_28','cell_29','cell_30_cell_31','cell_32','tumor_size','lymph_node_status']\n",
    "\n",
    "        if sys.argv[1].upper() == \"ALL\":\n",
    "            wpbc_df = prepare_df(\"data/wpbc.data\")\n",
    "            model_on_whole_data_set(wpbc_df, features)\n",
    "        elif sys.argv[1].upper() == \"HOLDOUT\":\n",
    "            wpbc_df = prepare_df(\"data/wpbc.data\")\n",
    "            model_using_holdout_validation(wpbc_df, features)\n",
    "        elif sys.argv[1].upper() == \"KFOLD\":\n",
    "            # implement my own k fold cross validation\n",
    "            wpbc_df = prepare_df(\"data/wpbc.data\")\n",
    "            model_using_kfold_cross_validation(wpbc_df, features, 5)\n",
    "        else:\n",
    "            parser.error(\"incorrect option\")\n",
    "            status = False\n",
    "    return status\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(0 if main() else 1)ing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
