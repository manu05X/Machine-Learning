{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Data\n",
    "\n",
    "Q> What do you understand by the sequential nature of data ?\n",
    "\n",
    "\n",
    "* i   Sequence of entities defines the data \n",
    "* ii  Every sequence has a different meaning \n",
    "* iii Size of input sequence can affect the output \n",
    "* iv  None of the above\n",
    "\n",
    "\n",
    "Correct Answer 1,2,3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN application\n",
    "\n",
    "Q> Recurrent neural networks are used for :\n",
    "\n",
    "   * Handwriting recognition \n",
    "   * Speech recognition \n",
    "   * Machine translation \n",
    "   * Image captioning and word prediction \n",
    "   * Music generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working of RNN\n",
    "\n",
    "Q> In this recurrent neural network how many different weight matrix sets are used ?\n",
    "\n",
    "ANS>  three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nth step in RNN\n",
    "\n",
    "Q> The generic nth step in RNN i.e.\n",
    " \n",
    " * a_n=A( w_xa * x_n + w_aa * a_n-1 + b_a)\n",
    " * Y_n=A’( w_ay * a_n + b_y)\n",
    "\n",
    "Why is there no term of x in Y_n ?\n",
    "\n",
    "\n",
    "* ANS> Because a_n term already contains the x value \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input sequence size\n",
    "\n",
    "Q> Why the input sequence in training example be large?\n",
    "\n",
    "ANS> To get more context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input sequence size 2\n",
    "\n",
    "Q> Why shouldn’t we then use complete training data as single sequence to predict next month’s passenger number ?\n",
    "\n",
    "\n",
    "  *  a> Because it would result in overfitting\n",
    "  *  b> Because it would result in underfitting\n",
    "  *  c> Because there would not be much training examples \n",
    "  *  d> Because the training time would be very large\n",
    "\n",
    "Correct Answer c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling of Test data\n",
    "\n",
    "Q> We should use scaler.fit_transform() to scale test data\n",
    "\n",
    "ANS> FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data shape\n",
    "\n",
    "Q> Consider that the data has 3 features and we have look_back=12 for 160 examples , what would be the shape of training dataset if training data is supposed to be generated by using one – third of actual data\n",
    "\n",
    "Options\n",
    "  *  a>    (41,3) \n",
    "  *  b>    (53,3)\n",
    "  *  c>    (94,3)\n",
    "  *  d>    (106,3)\n",
    "  \n",
    "Correct Answer a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No. of Weights matrices\n",
    "\n",
    "For the architecture described in lecture , how many weight matrix sets would be there ?\n",
    "\n",
    "\n",
    "ANS: 9\n",
    "\n",
    "\n",
    "There would be 4 weight matrices from input to 4 RNN units\n",
    "\n",
    "one weight matrix for each RNN from its previous state \n",
    "\n",
    "since there are 4 RNN units that makes it 4*1 = 4 \n",
    "\n",
    "then one weight matrix between RNN units and output unit\n",
    "\n",
    "Adding them up 4+4+1 = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No. of Parameters\n",
    "\n",
    "For architecture defined in lecture suppose there are 2 features in \n",
    "\n",
    "our dataset and look_back=12 , find the total number of parameters \n",
    "\n",
    "for our network?\n",
    "\n",
    "\n",
    "ANS\n",
    "118 * \n",
    "\n",
    "\n",
    "Since there are 2 features input layer will have 24 weights and 1 bias for each RNN unit , since there are 4 RNN units there would be (24+1)\\*4 =100 parameters at input layer , then each RNN unit will have one weight and one bias for its memory term , so total 4+4 =8 parameters and finally since output should have 2 features there would be two output units thus (4+1)*2=10 , thus total =100+8+10=118 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
